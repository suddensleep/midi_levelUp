{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Time Series Data from MIDI Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading all the file names and their channel mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import midi\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('channel_mappings.pkl', 'r') as f:\n",
    "    channel_mappings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midi_path = './midi/pop/'\n",
    "midi_files = os.listdir(midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(midi_files) == len(channel_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, we'll want to denote which instruments actually play melodies (basically anything that isn't a toneless percussion instrument, sound effect, or \"pad\" instrument). See the chart in [this](./flattening_tracks.ipynb) notebook for reference. If a given channel uses a \"non-melody instrument\", we will only extract the rhythmic information from that channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "melody_instruments = range(88) + range(104, 112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build new object types to contain the time series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EventSequence(object):\n",
    "    \"\"\"A container for a sequence of events. \n",
    "    \n",
    "    Abstract class, to be implemented via MelodySequence\n",
    "    or RhythmSequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_events = 0, mpqn = 500000):\n",
    "        \"\"\"Initialize object with default of zero events and \n",
    "        tempo at 120 bpm (500000 ms per beat).\n",
    "        \"\"\"\n",
    "        \n",
    "        self.num_events = num_events\n",
    "        self.mpqn = mpqn\n",
    "    \n",
    "    def add_event(self):\n",
    "        \"\"\"Add one new event.\"\"\"\n",
    "        \n",
    "        self.num_events += 1\n",
    "        \n",
    "    def set_mpqn(self, mpqn):\n",
    "        \"\"\"Change tempo in units of ms per beat.\"\"\"\n",
    "        \n",
    "        self.mpqn = mpqn\n",
    "        \n",
    "class MelodySequence(EventSequence):\n",
    "    \"\"\"A container for a melodic sequence. \n",
    "    Inherits from EventSequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_events = 0, mpqn = 500000):\n",
    "        super(MelodySequence, self).__init__(num_events, mpqn)\n",
    "        self.notes = []\n",
    "        \n",
    "    def add_note(self, note):\n",
    "        super(MelodySequence, self).add_event()\n",
    "        self.notes.append(note)\n",
    "        \n",
    "class RhythmSequence(EventSequence):\n",
    "    \"\"\"A container for a rhythmic sequence.\n",
    "    Inherits from EventSequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_events = 0, mpqn = 500000):\n",
    "        super(RhythmSequence, self).__init__(num_events, mpqn)\n",
    "        self.ticks = []\n",
    "        \n",
    "    def add_tick(self, tick):\n",
    "        super(RhythmSequence, self).add_event()\n",
    "        self.ticks.append(tick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of helper functions to actually extract the sequence of information from the given channel in the given MIDI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_rhythm_sequence(rhythm, mfile, channel):\n",
    "    \"\"\"Pull out the rhythms from the given channel in mfile.\n",
    "    \n",
    "    Inputs: rhythm is an empty RhythmSequence object\n",
    "            mfile is a midi.containers.Pattern object\n",
    "            channel is an integer channel number from 0-15\n",
    "            \n",
    "    Output: RhythmSequence object filled with ticks from mfile channel\n",
    "    \"\"\"\n",
    "    \n",
    "    mfile.make_ticks_abs()\n",
    "    for track in mfile:\n",
    "        for event in track:\n",
    "            if isinstance(event, midi.events.NoteOnEvent) and event.channel == channel and event.data[1] != 0:\n",
    "                rhythm.add_tick(event.tick)\n",
    "    rhythm.ticks = sorted(rhythm.ticks)\n",
    "    return rhythm\n",
    "\n",
    "def get_melody_sequence(melody, mfile, channel):\n",
    "    \"\"\"Pull out the melodies from the given channel in mfile.\n",
    "    \n",
    "    Inputs: melody is an empty MelodySequence object\n",
    "            mfile is a midi.containers.Pattern object\n",
    "            channel is an integer channel number from 0-15 (shouldn't be 9)\n",
    "            \n",
    "    Output: MelodySequence object filled with notes from mfile channel\n",
    "    \"\"\"\n",
    "    \n",
    "    mfile.make_ticks_abs()\n",
    "    for track in mfile:\n",
    "        for event in track:\n",
    "            if isinstance(event, midi.events.NoteOnEvent) and event.channel == channel and event.data[1] != 0:\n",
    "                melody.add_note((event.data[0], event.tick))\n",
    "    melody.notes = sorted(melody.notes, key = lambda x: x[1])\n",
    "    melody.notes = list(zip(*melody.notes)[0])\n",
    "    return melody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function below will loop through all of the assigned channels, create the relevant time series objects, and call the two helper functions above to get a rhythm and/or melody sequence for each instrument in the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequences(mfile, mapping):\n",
    "    \"\"\"Extract a list of melody sequences and rhythm sequences from mfile.\n",
    "    \n",
    "    Inputs: mfile is a midi.containers.Pattern object\n",
    "            mapping is a dictionary associating \"\"\"\n",
    "    melodies = []\n",
    "    rhythms = []\n",
    "    for channel in mapping:\n",
    "        instruments = mapping[channel]\n",
    "        if instruments == None:\n",
    "            continue\n",
    "        \n",
    "        rhythm = RhythmSequence()\n",
    "        melody = MelodySequence()\n",
    "        melodic_channel = True\n",
    "\n",
    "        for instrument in instruments:\n",
    "            if instrument not in melody_instruments:\n",
    "                melodic_channel = False\n",
    "                break\n",
    "\n",
    "        if melodic_channel and channel != 9:\n",
    "            melodies.append(get_melody_sequence(melody, mfile, channel).notes)\n",
    "\n",
    "        rhythms.append(get_rhythm_sequence(rhythm, mfile, channel).ticks)\n",
    "\n",
    "    return melodies, rhythms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a test run on the first two files in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfile1 = midi.read_midifile(midi_path + midi_files[0])\n",
    "mapping1 = channel_mappings[0]\n",
    "mfile2 = midi.read_midifile(midi_path + midi_files[1])\n",
    "mapping2 = channel_mappings[1]\n",
    "\n",
    "melodies1, rhythms1 = get_sequences(mfile1, mapping1)\n",
    "melodies2, rhythms2 = get_sequences(mfile2, mapping2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in general, we have more rhythm sequences than we have melody sequences. This is due to the fact that we extract rhythmic events for **all** instruments, but we only extract melodic information for the melodic subset of instruments defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rhythms1) - len(melodies1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rhythms2) - len(melodies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: [1],\n",
       "  1: [35],\n",
       "  2: [49],\n",
       "  3: None,\n",
       "  4: [5],\n",
       "  5: [25],\n",
       "  6: [49],\n",
       "  7: [119],\n",
       "  8: [124],\n",
       "  9: [1],\n",
       "  10: [98],\n",
       "  11: [24],\n",
       "  12: None,\n",
       "  13: None,\n",
       "  14: None,\n",
       "  15: None},\n",
       " {0: [0],\n",
       "  1: [0],\n",
       "  2: [48],\n",
       "  3: [33],\n",
       "  4: [73],\n",
       "  5: [66],\n",
       "  6: [27],\n",
       "  7: [89],\n",
       "  8: [125],\n",
       "  9: [0],\n",
       "  10: None,\n",
       "  11: None,\n",
       "  12: None,\n",
       "  13: None,\n",
       "  14: None,\n",
       "  15: None})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1, mapping2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to be careful about how to account for tempo changes within these songs. The rhythm sequences are in units of \"ticks\", which change from file to file and depend on the global resolution and the locally defined tempo of the song. This will be addressed in the following notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
