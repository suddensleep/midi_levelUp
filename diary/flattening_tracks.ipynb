{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading MIDI Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of these files structured them in at least two distinct ways. \n",
    "\n",
    "### Single-track files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "promises = midi.read_midifile('../midi/pop/10000_Promises.mid')\n",
    "print len(promises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first song, 10000 Promises, we see a file with a **single track** containing:\n",
    "\n",
    "#### KeySignatureEvent -- optional melodic key for the song (think number of sharps and flats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.KeySignatureEvent(tick=0, data=[0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SmpteOffsetEvent -- time code specification (not important for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.SmpteOffsetEvent(tick=0, data=[96, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SetTempoEvent -- the number of microseconds to assign to one beat (base 256 representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.SetTempoEvent(tick=0, data=[6, 162, 94])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          Note: if the microseconds per beat are \n",
    "\n",
    "$$6 \\cdot 256^{2} + 162 \\cdot 256 + 94 = 393216 + 41472 + 94 = 434782, $$\n",
    "          \n",
    "          then the beats per minute are \n",
    "$$60000000 \\div 434782 = 138.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following methods to easily transform units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434782"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][2].get_mpqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.00019320027047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][2].get_bpm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ProgramChangeEvent -- IMPORTANT -- change the instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.ProgramChangeEvent(tick=0, channel=0, data=[1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format: at time `tick`, assign instrument number `data` to `channel`, using the instrument numbers in the chart below.\n",
    "\n",
    "For example, the event above says to assign a Bright Acoustic Piano (the second instrument) to Channel 1 at time 0. Note the annoying differences in computer-counting versus musician-counting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![General MIDI Level 1 Instrument Patch Map](../pictures/GM1Patch.png)\n",
    "![General MIDI Level 1 Instrument Patch Map](../pictures/GM1Patch2.png)\n",
    "        \n",
    "        Graphics copyright Â© 1995-2015 MIDI Manufacturers Association Incorporated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ControlChangeEvent -- change some global feature of the instrument on `channel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.ControlChangeEvent(tick=0, channel=0, data=[7, 127])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format: at time `tick`, set control number `data[0]` to control value `data[1]` on `channel`.\n",
    "\n",
    "For example, the event above assigns maximum volume to Channel 1 at time 0.\n",
    "\n",
    "**Some other control number examples:**\n",
    "- 1 - Modulation Wheel - values: 0 - 127\n",
    "- 7 - Volume\n",
    "- 10 - Pan\n",
    "- 64 - Sustain pedal\n",
    "\n",
    "Note: control numbers 0 (MSB) and 32 (LSB) are used to switch banks (i.e. more sets of the same instruments or other instruments altogether). We will be mainly working with only one bank, so we can ignore these for now.\n",
    "\n",
    "#### NoteOnEvent -- play a note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.NoteOnEvent(tick=117, channel=0, data=[73, 53])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][38]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format: at time `tick`, play note `data[0]` at velocity `data[1]`.\n",
    "\n",
    "For example, the event above plays the note C#5 (about an octave above middle C#) with \"velocity\" 53 (out of 127) exactly 117 ms after the last event.\n",
    "\n",
    "Note: there are also **NoteOffEvent**s, to explicitly end the notes; these seem optional except in circumstances where there is no natural sonic decay (as there is for say, a guitar string) in the chosen instrument.\n",
    "\n",
    "#### EndOfTrackEvent -- just what it sounds like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.EndOfTrackEvent(tick=0, data=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note well:** \n",
    "\n",
    "You may have noticed that the tick values are *in relation to the last event*, and also that events may be simultaneous. We can use the following two methods to change the `tick` values from relative to absolute time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.EndOfTrackEvent(tick=63402, data=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises.make_ticks_abs()\n",
    "promises[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.EndOfTrackEvent(tick=0, data=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promises.make_ticks_rel()\n",
    "promises[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the channels are controlled from a single track in this setup, as opposed to the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-track files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "oceans = midi.read_midifile('../midi/pop/1000_Oceans.mid')\n",
    "print len(oceans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file, 1000 Oceans, contains multiple tracks ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(oceans)):\n",
    "    assert isinstance(oceans[i], midi.containers.Track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... some providing tempo-related information ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.Track(\\\n",
       "  [midi.TimeSignatureEvent(tick=0, data=[4, 2, 96, 8]),\n",
       "   midi.SequencerSpecificEvent(tick=0, data=[0, 0, 65]),\n",
       "   midi.SetTempoEvent(tick=0, data=[13, 98, 136]),\n",
       "   midi.SetTempoEvent(tick=105984, data=[13, 98, 136]),\n",
       "   midi.SetTempoEvent(tick=106136, data=[13, 128, 219]),\n",
       "   midi.SetTempoEvent(tick=106288, data=[13, 159, 185]),\n",
       "   midi.SetTempoEvent(tick=106440, data=[13, 191, 36]),\n",
       "   midi.SetTempoEvent(tick=106592, data=[13, 217, 195]),\n",
       "   midi.SetTempoEvent(tick=106744, data=[13, 250, 62]),\n",
       "   midi.SetTempoEvent(tick=106896, data=[14, 27, 83]),\n",
       "   midi.SetTempoEvent(tick=107048, data=[14, 55, 93]),\n",
       "   midi.SetTempoEvent(tick=107200, data=[14, 89, 150]),\n",
       "   midi.SetTempoEvent(tick=107352, data=[14, 124, 119]),\n",
       "   midi.SetTempoEvent(tick=107504, data=[14, 154, 9]),\n",
       "   midi.EndOfTrackEvent(tick=107504, data=[])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oceans[0].make_ticks_abs()\n",
    "oceans[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and others providing information about instruments and notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.Track(\\\n",
       "  [midi.TrackNameEvent(tick=0, text='\"1000 Oceans\" by Tori Amos', data=[34, 49, 48, 48, 48, 32, 79, 99, 101, 97, 110, 115, 34, 32, 98, 121, 32, 84, 111, 114, 105, 32, 65, 109, 111, 115]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=0, data=[0, 0]),\n",
       "   midi.ProgramChangeEvent(tick=0, channel=0, data=[0]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=0, data=[10, 63]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=0, data=[91, 74]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=0, data=[93, 7]),\n",
       "   midi.KeySignatureEvent(tick=0, data=[0, 0]),\n",
       "   midi.NoteOnEvent(tick=0, channel=0, data=[65, 103]),\n",
       "   midi.NoteOnEvent(tick=0, channel=0, data=[58, 103]),\n",
       "   midi.NoteOffEvent(tick=572, channel=0, data=[65, 65])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oceans[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.Track(\\\n",
       "  [midi.TrackNameEvent(tick=0, text='made MIDI by Chris Howe', data=[109, 97, 100, 101, 32, 77, 73, 68, 73, 32, 98, 121, 32, 67, 104, 114, 105, 115, 32, 72, 111, 119, 101]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=1, data=[0, 0]),\n",
       "   midi.ProgramChangeEvent(tick=0, channel=1, data=[0]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=1, data=[10, 63]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=1, data=[91, 78]),\n",
       "   midi.ControlChangeEvent(tick=0, channel=1, data=[93, 0]),\n",
       "   midi.KeySignatureEvent(tick=0, data=[0, 0]),\n",
       "   midi.NoteOnEvent(tick=0, channel=1, data=[46, 100]),\n",
       "   midi.NoteOnEvent(tick=0, channel=1, data=[53, 100]),\n",
       "   midi.NoteOffEvent(tick=572, channel=1, data=[46, 64])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oceans[2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a typical usage is to assign one track to each channel. The only exception in our sample file occurs in track 14, which seems to be pretty useless to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 midi.NoteOnEvent(tick=0, channel=1, data=[46, 87])\n",
      "14 midi.NoteOnEvent(tick=0, channel=1, data=[53, 87])\n",
      "14 midi.NoteOnEvent(tick=0, channel=2, data=[46, 100])\n",
      "14 midi.NoteOnEvent(tick=0, channel=3, data=[34, 59])\n",
      "14 midi.NoteOnEvent(tick=0, channel=4, data=[46, 115])\n",
      "14 midi.NoteOnEvent(tick=0, channel=9, data=[41, 46])\n",
      "14 midi.NoteOnEvent(tick=0, channel=9, data=[46, 27])\n",
      "14 midi.NoteOffEvent(tick=0, channel=1, data=[46, 0])\n",
      "14 midi.NoteOffEvent(tick=0, channel=1, data=[53, 0])\n",
      "14 midi.NoteOffEvent(tick=0, channel=2, data=[46, 0])\n",
      "14 midi.NoteOffEvent(tick=0, channel=3, data=[34, 0])\n",
      "14 midi.NoteOffEvent(tick=0, channel=4, data=[46, 0])\n",
      "14 midi.NoteOffEvent(tick=0, channel=9, data=[41, 0])\n",
      "14 midi.NoteOffEvent(tick=124, channel=9, data=[46, 64])\n",
      "14 midi.NoteOnEvent(tick=4, channel=9, data=[46, 27])\n",
      "14 midi.NoteOffEvent(tick=256, channel=9, data=[46, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(oceans)):\n",
    "    channel = None\n",
    "    for event in oceans[i]:\n",
    "        if 'channel' not in dir(event):\n",
    "            continue\n",
    "        elif channel == None:\n",
    "            channel = event.channel\n",
    "        else:\n",
    "            if channel != event.channel:\n",
    "                print i, event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, sometimes a number of tracks are of no interest to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.Track(\\\n",
       "  [midi.KeySignatureEvent(tick=0, data=[0, 0]),\n",
       "   midi.EndOfTrackEvent(tick=0, data=[])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oceans[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our overall plan will be to check for meta-events like instrument assignment and tempo settings, then to store the relevant note events from each channel to create a time series for each instrument's part."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
