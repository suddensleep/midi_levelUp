{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Markov Chains of Various Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load the full list of pickled sequences *(this may take a moment or two)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('all_melodies.pkl', 'r') as f:\n",
    "    all_melodies = pickle.load(f)\n",
    "with open('all_rhythms.pkl', 'r') as g:\n",
    "    all_rhythms = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(all_melodies) == len(all_rhythms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a **Markov** object that will store Markov chain information for chains of various orders and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Markov(object):\n",
    "    \"\"\"A container for holding Markov chains of various orders, \n",
    "    where the events in the given 'current state' may occur temporally \n",
    "    before and/or after the note to be examined as the 'next state'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, before = 0, after = 0, mode = 0):\n",
    "        \"\"\"Initialize a Markov object with `before` notes before the\n",
    "        space to be filled, `after` notes after the space to be filled,\n",
    "        and with `mode` equal to 0, 1 or 2 according to whether the 'current\n",
    "        state' contains notes only before, only after, or both before and after\n",
    "        the note to be filled in the 'next state'.\n",
    "        \n",
    "        Inputs: \n",
    "        before - int - number of notes before next state\n",
    "        after - int - number of notes after next state\n",
    "        mode - int in range(3) - mode of the chain(see above)\n",
    "        \n",
    "        Outputs - Markov object\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode == 0:\n",
    "            assert before != 0 and after == 0\n",
    "        elif mode == 1:\n",
    "            assert before == 0 and after != 0\n",
    "        else:\n",
    "            assert before != 0 and after != 0\n",
    "\n",
    "        self.before = before\n",
    "        self.after = after\n",
    "        self.mode = mode\n",
    "        self.state_dict = {}\n",
    "        \n",
    "    def add_data(self, seq, result):\n",
    "        \"\"\"Add one (current state -> next state) instance to the dictionary.\n",
    "        Store each instance as a tally, to be normalized later.\n",
    "        \n",
    "        Inputs:\n",
    "        seq - if mode = 0, seq is a tuple of length before\n",
    "              if mode = 1, seq is a tuple of length after\n",
    "              if mode = 2, seq is a list of length two, with first element\n",
    "                           a tuple of length before and with second element\n",
    "                           a tuple of length after\n",
    "        result - int - single event\n",
    "        \n",
    "        Outputs:\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.mode == 0:\n",
    "            assert isinstance(seq, tuple) and len(seq) == self.before\n",
    "        elif self.mode == 1:\n",
    "            assert isinstance(seq, tuple) and len(seq) == self.after\n",
    "        else:\n",
    "            assert (isinstance(seq, tuple) and len(seq) == 2 and\n",
    "                    isinstance(seq[0], tuple) and len(seq[0]) == self.before and\n",
    "                    isinstance(seq[1], tuple) and len(seq[1]) == self.after)\n",
    "            \n",
    "        if seq not in self.state_dict:\n",
    "            self.state_dict[seq] = {result: 1}\n",
    "        elif result in self.state_dict[seq]:\n",
    "            self.state_dict[seq][result] += 1\n",
    "        else:\n",
    "            self.state_dict[seq][result] = 1\n",
    "            \n",
    "    def normalize(self):\n",
    "        \"\"\"Convert the state_dict dictionary from counts to probabilities.\n",
    "        \n",
    "        Inputs: None\n",
    "        \n",
    "        Outputs: None\n",
    "        \"\"\"\n",
    "        \n",
    "        for seq in self.state_dict:\n",
    "            sum = 0\n",
    "            for result in self.state_dict[seq]:\n",
    "                sum += self.state_dict[seq][result]\n",
    "            for result in self.state_dict[seq]:\n",
    "                self.state_dict[seq][result] /= float(sum)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, we want to consider chords as representing all N notes in the chord equally. For example, if a chord of three simultaneous note occurs as a 'next state', we will count each of the three component notes of that chord as equally likely to occur after the given 'current state'. \n",
    "\n",
    "In order to use `itertools.product` on the slice of the sequence we are looking for, we'll convert *all* the integer events to singleton lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for melody in all_melodies:\n",
    "    for i in range(len(melody)):\n",
    "        if isinstance(melody[i], int):\n",
    "            melody[i] = [melody[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72], [73], [75], [68], [73], [76], [68], [73], [68], [71], [76], [68], [71], [68], [70], [76], [68], [70], [70], [73], [78], [70], [73], [65], [58], [60], [62]]\n"
     ]
    }
   ],
   "source": [
    "print all_melodies[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main function used to actually extract current and next states from a raw sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def iterate_melody(mel, mark, before, after):\n",
    "    \"\"\"Adds one new observation to the Markov chain training process.\n",
    "    \n",
    "    Inputs: \n",
    "    mel - a list of lists representing a melody sequence\n",
    "    mark - a Markov object\n",
    "    before - integer, how many notes before next state\n",
    "    after - integer, how many notes after next state\n",
    "    \n",
    "    Outputs:\n",
    "    None (instead adds data to markov object directly)\n",
    "    \"\"\"\n",
    "    \n",
    "    full_length = before + after + 1\n",
    "    for i in range(len(mel) - full_length):\n",
    "        for seq in itertools.product(*mel[i:i + full_length]):\n",
    "            before_seq, after_seq, val = seq[:before], seq[-after:], seq[before]\n",
    "            mode = mark.mode\n",
    "            if mode == 0:\n",
    "                mark.add_data(before_seq, val)\n",
    "            elif mode == 1:\n",
    "                mark.add_data(after_seq, val)\n",
    "            else:\n",
    "                mark.add_data((before_seq, after_seq), val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the general implementation for turning a sequence into a Markov dictionary:\n",
    "\n",
    "1. Create Markov object with the desired tail lengths\n",
    "2. Call iterate_melody on the sequence\n",
    "3. Normalize the Markov dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(58,): {60: 1.0}, (65,): {58: 1.0}, (72,): {73: 1.0}, (73,): {68: 0.2, 75: 0.2, 76: 0.2, 78: 0.2, 65: 0.2}, (68,): {73: 0.3333333333333333, 70: 0.3333333333333333, 71: 0.3333333333333333}, (75,): {68: 1.0}, (70,): {73: 0.5, 76: 0.25, 70: 0.25}, (76,): {68: 1.0}, (71,): {68: 0.5, 76: 0.5}, (78,): {70: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "markov = Markov(1, 0, 0)\n",
    "iterate_melody(all_melodies[0], markov, before = 1, after = 0)\n",
    "markov.normalize()\n",
    "print markov.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(71, 68): {70: 1.0}, (68, 71): {68: 0.5, 76: 0.5}, (76, 68): {73: 0.3333333333333333, 70: 0.3333333333333333, 71: 0.3333333333333333}, (68, 73): {68: 0.5, 76: 0.5}, (68, 70): {76: 0.5, 70: 0.5}, (70, 70): {73: 1.0}, (71, 76): {68: 1.0}, (70, 73): {65: 0.5, 78: 0.5}, (78, 70): {73: 1.0}, (72, 73): {75: 1.0}, (65, 58): {60: 1.0}, (73, 75): {68: 1.0}, (73, 68): {71: 1.0}, (70, 76): {68: 1.0}, (75, 68): {73: 1.0}, (73, 78): {70: 1.0}, (73, 76): {68: 1.0}, (73, 65): {58: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "markov = Markov(2, 0, 0)\n",
    "iterate_melody(all_melodies[0], markov, before = 2, after = 0)\n",
    "markov.normalize()\n",
    "print markov.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72], [73], [75], [68], [73], [76], [68], [73], [68], [71], [76], [68], [71], [68], [70], [76], [68], [70], [70], [73], [78], [70], [73], [65], [58], [60], [62]]\n"
     ]
    }
   ],
   "source": [
    "print all_melodies[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts seem to be right (but certainly check them yourselves if you don't believe me!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out all different modes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(58,): {65: 1.0}, (65,): {73: 1.0}, (60,): {58: 1.0}, (73,): {72: 0.2, 68: 0.4, 70: 0.4}, (68,): {73: 0.16666666666666666, 75: 0.16666666666666666, 76: 0.5, 71: 0.16666666666666666}, (75,): {73: 1.0}, (70,): {68: 0.5, 78: 0.25, 70: 0.25}, (76,): {73: 0.3333333333333333, 70: 0.3333333333333333, 71: 0.3333333333333333}, (71,): {68: 1.0}, (78,): {73: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "markov = Markov(0, 1, 1)\n",
    "iterate_melody(all_melodies[0], markov, before = 0, after = 1)\n",
    "markov.normalize()\n",
    "print markov.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{((75, 68), (76, 68)): {73: 1.0}, ((73, 78), (73, 65)): {70: 1.0}, ((70, 76), (70, 70)): {68: 1.0}, ((68, 73), (71, 76)): {68: 1.0}, ((71, 68), (76, 68)): {70: 1.0}, ((73, 76), (73, 68)): {68: 1.0}, ((71, 76), (71, 68)): {68: 1.0}, ((72, 73), (68, 73)): {75: 1.0}, ((76, 68), (68, 71)): {73: 1.0}, ((76, 68), (70, 73)): {70: 1.0}, ((78, 70), (65, 58)): {73: 1.0}, ((68, 71), (70, 76)): {68: 1.0}, ((68, 71), (68, 71)): {76: 1.0}, ((73, 75), (73, 76)): {68: 1.0}, ((70, 73), (70, 73)): {78: 1.0}, ((70, 70), (78, 70)): {73: 1.0}, ((68, 70), (73, 78)): {70: 1.0}, ((68, 70), (68, 70)): {76: 1.0}, ((68, 73), (68, 73)): {76: 1.0}, ((76, 68), (68, 70)): {71: 1.0}, ((73, 68), (76, 68)): {71: 1.0}, ((70, 73), (58, 60)): {65: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "markov = Markov(2, 2, 2)\n",
    "iterate_melody(all_melodies[0], markov, before = 2, after = 2)\n",
    "markov.normalize()\n",
    "print markov.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work pretty well for melodies! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('all_melodies.pkl', 'w') as f:\n",
    "    pickle.dump(all_melodies, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we train a Markov chain on ALL the melodies in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mark_a = Markov(1, 0, 0)\n",
    "for i in range(len(all_melodies)):\n",
    "    iterate_melody(all_melodies[i], mark_a, before = 1, after = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) {13: 1.3626020248266096e-05, 14: 1.3626020248266096e-05, 16: 8.175612148959658e-05, 17: 1.3626020248266096e-05, 18: 6.131709111719744e-05, 19: 3.4065050620665245e-05, 20: 0.0014852362070610046, 21: 4.769107086893134e-05, 22: 0.0006336099415443734, 23: 0.00044284565806864816, 24: 0.0005246017795582448, 25: 0.007616945318780748, 26: 0.009817547588875722, 27: 0.0191104933981932, 28: 0.012297483274060153, 29: 0.016208151085312525, 30: 0.03929062938587529, 31: 0.036715311558952995, 32: 0.40460423224188935, 33: 0.06311572578996856, 34: 0.06838218261592341, 35: 0.03385384730681712, 36: 0.021372412759405372, 37: 0.042996906893403665, 38: 0.008509449645042178, 39: 0.033404188638624335, 40: 0.005722928504271761, 41: 0.003011350474866807, 42: 0.005491286160051238, 43: 0.0023164234422052366, 44: 0.08025044625216317, 45: 0.007821335622504741, 46: 0.00507569254247912, 47: 0.0015261142678058028, 48: 0.001260406872964614, 49: 0.0012944719235852792, 50: 0.000565479840303043, 51: 0.006976522367112241, 52: 0.0007630571339029014, 53: 0.0029159683331289447, 54: 0.011234653694695397, 55: 0.001410293095695541, 56: 0.0143686383517966, 57: 0.000565479840303043, 58: 0.002541252776301627, 59: 0.0030249764951150735, 60: 0.003815285669514507, 61: 0.001389854065323142, 62: 0.0008107482047718328, 63: 0.0060158879396094815, 64: 0.000858439275640764, 65: 0.0009606344275027598, 66: 0.0011582117211026183, 67: 0.0007085530529098371, 68: 0.001260406872964614, 69: 0.00017713826322745928, 70: 0.000422406627696249, 71: 0.0003474635163307855, 72: 0.0004019675973238498, 73: 0.0001975772935998584, 74: 0.00021801632397225754, 75: 0.0013694150349507427, 76: 8.856913161372964e-05, 77: 0.000143073212606794, 78: 4.769107086893134e-05, 79: 8.175612148959658e-05, 80: 2.0439030372399144e-05, 81: 4.769107086893134e-05, 82: 0.000143073212606794, 83: 4.087806074479829e-05, 84: 6.813010124133049e-05, 85: 4.087806074479829e-05, 86: 2.0439030372399144e-05, 87: 6.131709111719744e-05, 88: 1.3626020248266096e-05, 89: 6.813010124133048e-06, 90: 2.0439030372399144e-05, 91: 1.3626020248266096e-05, 92: 1.3626020248266096e-05, 93: 2.0439030372399144e-05, 94: 2.7252040496532193e-05, 95: 6.813010124133048e-06, 97: 1.3626020248266096e-05, 98: 6.813010124133048e-06, 99: 2.0439030372399144e-05, 100: 2.7252040496532193e-05, 101: 2.0439030372399144e-05, 102: 2.0439030372399144e-05, 103: 2.0439030372399144e-05, 114: 6.813010124133048e-06, 115: 4.087806074479829e-05}\n",
      "(124,) {59: 0.011904761904761906, 74: 0.011904761904761906, 77: 0.011904761904761906, 112: 0.09523809523809525, 81: 0.011904761904761906, 115: 0.011904761904761906, 116: 0.05952380952380953, 56: 0.011904761904761906, 120: 0.16666666666666669, 121: 0.1785714285714286, 122: 0.04761904761904762, 123: 0.14285714285714288, 124: 0.2023809523809524, 125: 0.02380952380952381, 52: 0.011904761904761906}\n"
     ]
    }
   ],
   "source": [
    "mark_a.normalize()\n",
    "for key in mark_a.state_dict.keys()[:2]:\n",
    "    print key, mark_a.state_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the note '32' is followed by a large variety of other notes throughout the corpus. As such, the probability of any one such note is pretty slim, compared to the toy examples above. Let's see what the most likely notes are ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 91 artists>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFV1JREFUeJzt3WGMXNd9nvHn7dIqKtmJEkS1GpqpFJuprcBJrTQMU8XN\nyCHUjVCYAvxBFuw6tQOVKErbLYKWZgpEq49CYdQNBKusyxiBoYQfXFlYA3JIqe4AQupIZMpIakwq\nZBy2JCXLimSrkQsjS/DfD3NJDle7M7O7M7vauc8PWHDuPffMnDNcvHP23HvnpKqQJLXH39joBkiS\n1pfBL0ktY/BLUssY/JLUMga/JLWMwS9JLTM0+JPMJjmZ5FSSfQOO+/kkF5J8qG/fmSTPJjme5Olx\nNVqStHpbBhUmmQEeBHYB54GjSear6sQSxz0A/MGipyigU1Wvjq/JkqS1GDbi3wGcrqozVbUAHAJ2\nL3HcJ4EvAy8vUZa1NVGSNE7Dgn8rcLZv+1yz77IkW+l9GDzU7Oq/FbiAJ5IcS3LvGtsqSRqDgVM9\nXB3iy/kc8JmqqiTh6hH+bVX1YpIbgMeTnKyqJ1fbWEnS2g0L/vPAtr7tbfRG/f1+DjjUy3x+DPjV\nJAtVNV9VLwJU1ctJvkJv6uiq4E/ilwVJ0ipU1aqm0odN9RwDtie5Kck1wN3A/KIX/smqurmqbqY3\nz/8vqmo+ybVJ3gaQ5DrgDuC5ZRo/tT/33XffhrfB/tm/tvWtDf1bi4Ej/qq6kGQvcBiYAQ5W1Ykk\ne5ryAwOq3wg80vwlsAV4uKqOrKm1kqQ1GzbVQ1V9Dfjaon1LBn5Vfbzv8beAv7/WBkqSxss7dyes\n0+lsdBMmyv5tXtPcN5j+/q1F1jpXtOYGJLXRbZCkzSYJNaGTu5KkKWPwS1LLGPyS1DIGvyS1jMEv\nSS1j8EtSyxj8ktQyBr8ktYzBL0ktY/BLUssY/JLUMga/JLWMwS9JLWPwS1LLDA3+JLNJTiY5lWTf\ngON+PsmFJB9aaV1J0voZGPxJZoAHgVngFuCeJO9Z5rgHgD9YaV1J0voaNuLfAZyuqjNVtQAcAnYv\ncdwn6S20/vIq6mqCklz1I0nDgn8rcLZv+1yz77IkW+kF+kPNrkvLaQ2tq/VSXPlvkdR2wxZbHyUt\nPgd8pqoqvSHlpWHlyEkzNzd3+XGn03GtTElapNvt0u12x/JcA9fcTbITmKuq2WZ7P3Cxqh7oO+Zb\nXAn7HwP+H3Av8J1hdZv9rrk7Qb3P4kvvb/C9lqbDWtbcHTbiPwZsT3IT8AJwN3BP/wFV9ZN9Dfki\n8NWqmk+yZVhdSdL6Gxj8VXUhyV7gMDADHKyqE0n2NOUHVlp3fE2XJK3GwKmedWmAUz0T5VSPNJ3W\nMtXjnbuS1DIGvyS1jMEvSS1j8EtSyxj8ktQyBr8ktYzBL0ktY/BLUssY/JLUMga/JLWMwS9JLWPw\nS1LLGPyS1DIGvyS1jMEvSS1j8EtSywwN/iSzSU4mOZVk3xLlu5M8k+R4kj9O8oG+sjNJnm3Knh53\n4yVJKzdssfUZ4HlgF3AeOArc07+EYpLrqur7zeP3Al+pqnc1238B/FxVvTrgNVyBa4JcgUuaTpNc\ngWsHcLqqzlTVAnAI2N1/wKXQb7wV+MvF7VtNwyRJkzEs+LcCZ/u2zzX7rpLkriQngK8Bn+orKuCJ\nJMeS3LvWxkqS1m7LkPKR5gWq6lHg0STvB74E/L2m6LaqejHJDcDjSU5W1ZOL68/NzV1+3Ol06HQ6\no7ysJLVGt9ul2+2O5bmGzfHvBOaqarbZ3g9crKoHBtT5c2BHVb2yaP99wOtV9dlF+53jnyDn+KXp\nNMk5/mPA9iQ3JbkGuBuYX/Ti70wvXUhyK0BVvZLk2iRva/ZfB9wBPLeaRkqSxmfgVE9VXUiyFzgM\nzAAHq+pEkj1N+QHgQ8DHkiwArwMfbqrfCDzSfCZsAR6uqiOT6YYkaVQDp3rWpQFO9UyUUz3SdJrk\nVI8kacoY/JLUMga/JLWMwS9JLWPwS1LLGPyS1DIGvyS1jMEvSS1j8EtSyxj8ktQyBr8ktYzBL0kt\nY/BLUssY/JLUMga/JLWMwS9JLTM0+JPMJjmZ5FSSfUuU707yTJLjSf44yQdGrStJWn/DFlufAZ4H\ndgHngaPAPVV1ou+Y66rq+83j9wJfqap3jVK3qeMKXBPkClzSdJrkClw7gNNVdaaqFoBDwO7+Ay6F\nfuOtwF+OWleStP6GBf9W4Gzf9rlm31WS3JXkBPA14FMrqStJWl9bhpSPNC9QVY8CjyZ5P/ClJO9e\nSSPm5uYuP+50OnQ6nZVUl6Sp1+126Xa7Y3muYXP8O4G5qppttvcDF6vqgQF1/pzeNM/2Ueo6xz9Z\nzvFL02mSc/zHgO1JbkpyDXA3ML/oxd+ZXrqQ5FaAqnpllLqSpPU3cKqnqi4k2QscBmaAg1V1Isme\npvwA8CHgY0kWgNeBDw+qO7muSJJGMXCqZ10a4FTPRDnVI02nSU71SJKmjMEvSS1j8EtSyxj8ktQy\nBr8ktYzBL0ktY/BLUssY/JLUMga/JLWMwS9JLWPwS1LLGPyS1DIGvyS1jMEvSS1j8EtSywwN/iSz\nSU4mOZVk3xLlH0nyTJJnk/xhkp/pKzvT7D+e5OlxN16StHIDV+BKMgM8COwCzgNHk8wvWknrW8A/\nqqrXkswC/xnY2ZQV0KmqV8ffdEnSagwb8e8ATlfVmapaAA4Bu/sPqKpvVNVrzeZTwDsWPceqVoiR\nJE3GsODfCpzt2z7X7FvOrwOP9W0X8ESSY0nuXV0TJUnjNHCqhyuLtQ6V5HbgE8Btfbtvq6oXk9wA\nPJ7kZFU9uYp2SpLGZFjwnwe29W1vozfqv0pzQvcLwGxVfffS/qp6sfn35SRfoTd19Ibgn5ubu/y4\n0+nQ6XRG7oAktUG326Xb7Y7luVK1/KA+yRbgeeBXgBeAp4F7+k/uJvkJ4OvAR6vqj/r2XwvMVNVf\nJbkOOALcX1VHFr1GDWqD1iYJV/5wC77X0nRIQlWt6hzqwBF/VV1Ishc4DMwAB6vqRJI9TfkB4LeA\nHwEe6oUMC1W1A7gReKTZtwV4eHHoS5LW38AR/7o0wBH/RDnil6bTWkb83rkrSS1j8EtSyxj8ktQy\nBr8ktYzBL0ktY/BLUssY/JLUMga/JLWMwS9JLWPwS1LLGPyS1DIGvyS1jMEvSS1j8EtSyxj8ktQy\nBr8ktczQ4E8ym+RkklNJ9i1R/pEkzyR5NskfNuvvjlRXkrT+hq25O0Nvzd1d9BZeP8ob19z9ReCb\nVfVakllgrqp2jlK3qe8KXBPkClzSdJrkClw7gNNVdaaqFoBDwO7+A6rqG1X1WrP5FPCOUetKktbf\nsODfCpzt2z7X7FvOrwOPrbKuJGkdbBlSPvK8QJLbgU8At620riRp/QwL/vPAtr7tbfRG7ldpTuh+\nAZitqu+upC7A3Nzc5cedTodOpzOkWZLULt1ul263O5bnGnZydwu9E7S/ArwAPM0bT+7+BPB14KNV\n9Ucrqdsc58ndCfLkrjSd1nJyd+CIv6ouJNkLHAZmgINVdSLJnqb8APBbwI8AD/VChoWq2rFc3dU0\nUpI0PgNH/OvSAEf8E+WIX5pOk7ycU5I0ZQx+SWoZg1+SWsbgl6SWMfglqWUMfklqGYNfklrG4Jek\nljH4JallDH5JahmDX5JaxuCXpJYx+CWpZQx+SWoZg1+SWsbgl6SWGRr8SWaTnExyKsm+JcrfneQb\nSX6Q5DcWlZ1J8myS40meHmfDJUmrM3DpxSQzwIPALnqLpx9NMr9oCcVXgE8Cdy3xFAV0qurVMbVX\nkrRGw0b8O4DTVXWmqhaAQ8Du/gOq6uWqOgYsLPMcq1oaTJI0GcOCfytwtm/7XLNvVAU8keRYkntX\n2jhJ0vgNnOrhyirdq3VbVb2Y5Abg8SQnq+rJxQfNzc1dftzpdOh0Omt8WUmaLt1ul263O5bnStXy\n2Z5kJzBXVbPN9n7gYlU9sMSx9wGvV9Vnl3muJcuT1KA2aG2ScOXzO/heS9MhCVW1qqn0YVM9x4Dt\nSW5Kcg1wNzC/XDsWNeraJG9rHl8H3AE8t5pGSpLGZ+BUT1VdSLIXOAzMAAer6kSSPU35gSQ3AkeB\nHwIuJvk0cAvwt4FHeiNOtgAPV9WRyXVFkjSKgVM969IAp3omyqkeaTpNcqpHkjRlDH5JahmDX5Ja\nxuCXpJYx+CWpZQx+SWoZg1+SWsbgl6SWMfglqWUMfklqGYNfklrG4JekljH4JallDH5JahmDX5Ja\nxuCXpJYZGvxJZpOcTHIqyb4lyt+d5BtJfpDkN1ZSV5K0/oYttj4DPA/sAs7TW2Lxnqo60XfMDcDf\nBe4CvntpMfVR6jbHuQLXBLkClzSdJrkC1w7gdFWdqaoF4BCwu/+Aqnq5qo4BCyutK0laf8OCfytw\ntm/7XLNvFGupK0makC1DytcyLzBy3bm5ucuPO50OnU5nDS8rSdOn2+3S7XbH8lzD5vh3AnNVNdts\n7wcuVtUDSxx7H/B63xz/SHWd458s5/il6TTJOf5jwPYkNyW5BrgbmF+uHWuoK0laJwOneqrqQpK9\nwGFgBjhYVSeS7GnKDyS5kd4VOz8EXEzyaeCWqnp9qbqT7IwkabiBUz3r0gCneibKqR5pOk1yqkeS\nNGUMfklqGYNfklrG4JekljH4Jallht25K41F7+qiHq8skjaWI36tIwNfejMw+CWpZQx+SWoZg1+S\nWsbgl6SW8aqelvIqG6m9HPG3moEvtZEj/pbpH+lLaidH/K3jKF9qO4NfklpmaPAnmU1yMsmpJPuW\nOea3m/Jnkryvb/+ZJM8mOZ7k6XE2XJK0OgPn+JPMAA8Cu4DzwNEk8/1LKCa5E3hXVW1P8gvAQ8DO\npriATlW9OpHWS5JWbNiIfwdwuqrOVNUCcAjYveiYDwK/C1BVTwHXJ3l7X7lnEyXpTWRY8G8FzvZt\nn2v2jXpMAU8kOZbk3rU0VJI0HsMu5xz1EpDlRvW/VFUvJLkBeDzJyap6cvFBc3Nzlx93Oh06nc6I\nLytJ7dDtdul2u2N5rgy6azPJTmCuqmab7f3Axap6oO+Y/wR0q+pQs30S+OWqemnRc90HvF5Vn120\nv7xzdHJ61+1fen8vPb70Od17vB7v/5V2rM/rSdMuCVW1qqn0YVM9x4DtSW5Kcg1wNzC/6Jh54GNN\nQ3YC36uql5Jcm+Rtzf7rgDuA51bTSEnS+Ayc6qmqC0n2AoeBGeBgVZ1IsqcpP1BVjyW5M8lp4PvA\nx5vqNwKPNHeKbgEerqojk+qIxmvxHb6O0qXpMXCqZ10a4FTPRK12qmdxvbX+HznVI43XWqZ6/K6e\nKeI3bkoahV/ZMHUMfEmDOeKfUn4Lp6TlGPxTrX8+f3krmSJyOkna/JzqUWMlIW7gS5uZwS9JLWPw\nS1LLGPyS1DIGvyS1jFf16CpeBipNP4N/k1jf784Z7TJQSZuTUz2bSuGllJLWyhH/JufUjKSVMvin\nglMzo/CrpqUeg3+TcqQ/2PJfLdH/FdVSOw2d408ym+RkklNJ9i1zzG835c8ked9K6mqwJMuEvKPV\n4XyPpKUMDP4kM8CDwCxwC3BPkvcsOuZO4F1VtR3458BDo9Ztg9Usjnwp7K8E/sYH2HIfQOPp3+rr\nT/ovn3Etbv1mNM19g+nv31oMG/HvAE5X1ZmqWgAOAbsXHfNB4HcBquop4PokN45Yd+qt/pdv48P+\nakuv0nX77bdfFb6jB3Kt8Pil6k/+PRr0/7deHz6TMu3BOO39W4thwb8VONu3fa7ZN8oxPz5CXW16\n9wGL/yJY6Td9jifAxxHEi/+auP/++4c835vtA1oabljwj/pbvTmHPBO2VHCs5zTF+npjgK+0n4vf\nm1Hfq2EfOqPWf+NzFIs/2JZrz7C2r7RPo5re3ydN0rCres4D2/q2t9EbuQ865h3NMW8ZoS7QjitU\nluvj8n3PEo+X2jfK40nWu39IOcvsX+o1Brv6vVrJayxdPvy9H6Vta/vdHffv/kqf7/777x9+0CY2\n7f1brWHBfwzYnuQm4AXgbuCeRcfMA3uBQ0l2At+rqpeSvDJC3VWvEi9JWp2BwV9VF5LsBQ4DM8DB\nqjqRZE9TfqCqHktyZ5LTwPeBjw+qO8nOSJKGi3cvSlK7bOiXtE3TDV5JtiX570n+NMn/SvKpZv+P\nJnk8yZ8lOZLk+o1u61okmUlyPMlXm+2p6V+S65N8OcmJJN9M8gtT1r/9ze/nc0l+L8nf3Mz9S/I7\nSV5K8lzfvmX70/T/VJM5d2xMq0ezTN/+ffO7+UySR5L8cF/Zivq2YcGf6bvBawH411X108BO4F82\n/fkM8HhV/RTw35rtzezTwDe5cunLNPXvPwKPVdV7gJ8BTjIl/WvOtd0L3FpV76U3/fphNnf/vkgv\nP/ot2Z8kt9A7z3hLU+fzSd7M3068VN+OAD9dVT8L/BmwH1bXt43s+FTd4FVV366qP2kevw6coHff\nwuUb3Jp/79qYFq5dkncAdwL/hSuXs0xF/5rR0/ur6negd46qql5jSvoH/F96g5Nrk2wBrqV30cWm\n7V9VPQl8d9Hu5fqzG/j9qlqoqjPAaXoZ9Ka0VN+q6vGquthsPkXvCkpYRd82MvhHuTlsU2pGV++j\n95/z9qp6qSl6CXj7BjVrHP4D8G+Ai337pqV/NwMvJ/likv+Z5AtJrmNK+ldVrwKfBf4PvcD/XlU9\nzpT0r89y/flxrr6cfLPnzSeAx5rHK+7bRgb/VJ5VTvJW4L8Cn66qv+ovq96Z9E3Z7yT/BPhOVR1n\nmYvXN3P/6F3hdivw+aq6ld4ValdNe2zm/iV5J/CvgJvoBcVbk3y0/5jN3L+ljNCfTdnXJP8O+Ouq\n+r0Bhw3s20YG/yg3h20qSd5CL/S/VFWPNrtfSu+7i0jyd4DvbFT71ugfAh9M8hfA7wMfSPIlpqd/\n54BzVXW02f4yvQ+Cb09J//4B8D+q6pWqugA8Avwi09O/S5b7fVzqRtPz69y2NUvyz+hNt36kb/eK\n+7aRwX/55rAk19A7OTG/ge1Zk/RumTwIfLOqPtdXNA/8WvP414BHF9fdDKrqN6tqW1XdTO+k4Ner\n6p8yPf37NnA2yU81u3YBfwp8lSnoH70T1TuT/K3md3UXvZP009K/S5b7fZwHPpzkmiQ3A9uBpzeg\nfauWZJbeVOvuqvpBX9HK+1ZVG/YD/CrwPL2TEfs3si1j6Msv0Zv7/hPgePMzC/wo8AS9s/BHgOs3\nuq1j6OsvA/PN46npH/CzwFHgGXoj4h+esv79W3ofZs/RO/H5ls3cP3p/eb4A/DW984UfH9Qf4Deb\nrDkJ/OONbv8K+/YJ4BTwv/vy5fOr7Zs3cElSy7yZr2OVJE2AwS9JLWPwS1LLGPyS1DIGvyS1jMEv\nSS1j8EtSyxj8ktQy/x/WNmlzCtugxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1651fbb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key = mark_a.state_dict.keys()[0]\n",
    "D = mark_a.state_dict[key]\n",
    "\n",
    "plt.bar(D.keys(), D.values(), align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like it would be pretty typical, a normal looking density centered around the note 32 itself, with an outlier second mode exactly one octave up, and a bit of a longer tail on the right side, where there is more room to have a tail. Cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('mark100.pkl', 'w') as f:\n",
    "    pickle.dump(mark_a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this pickled file of 'counts' is much smaller (245K) than the collection of pickled sequences (~500M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##DANGER: THIS LOOP CRASHES KERNEL AT THIS STAGE\n",
    "\"\"\"\n",
    "for before in range(4):\n",
    "    for after in range(4):\n",
    "        if before == 0:\n",
    "            if after == 0:\n",
    "                continue\n",
    "            mode = 1\n",
    "        elif after == 0:\n",
    "            mode = 0\n",
    "        else:\n",
    "            mode = 2\n",
    "        mark = Markov(before, after, mode)\n",
    "        for k in range(len(all_melodies)):\n",
    "            iterate_melody(all_melodies[k], mark, before = before, after = after)\n",
    "        mark.normalize()\n",
    "        with open('markov' + str(before) + str(after) + str(mode) + '.pkl', 'w') as f:\n",
    "            pickle.dump(mark, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As it turns out, this way of storing the information isn't great either; with Markov chains of order >= 4, the kernel crashed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing left to ponder is how **absolutely** we want to represent note position in these chains. For example, is the sequence C-D-E pretty much equivalent to the sequence G-A-B? Can we count them as one? And if so, will this improve the runtime for these training steps?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
